\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{LIST OF TABLES}{xii}{section*.1}}
\@writefile{toc}{\contentsline {chapter}{LIST OF FIGURES}{xiii}{section*.2}}
\citation{sparcc}
\citation{domen}
\@writefile{toc}{\contentsline {chapter}{LIST OF ABBREVIATIONS}{xxii}{section*.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Network Notation and Basic Summarization}{2}{section.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Representing relational information}{2}{subsection.1.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces {\bf  A simple network example (coauthorship).} A co-authorship network with an edge between a pair of people if they have written a paper together.}}{2}{figure.1.1}}
\newlabel{fig:social}{{1.1}{2}{{\bf A simple network example (coauthorship).} A co-authorship network with an edge between a pair of people if they have written a paper together}{figure.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Network Summary Statistics}{3}{subsection.1.1.2}}
\citation{cytofkit}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces {\bf  Hairball network.} Networks are often noisy data structures and lack an immediate straight forward structural interpretation. [Image from \url  {https://cs.umd.edu}.]}}{4}{figure.1.2}}
\newlabel{fig:Hairball}{{1.2}{4}{{\bf Hairball network.} Networks are often noisy data structures and lack an immediate straight forward structural interpretation. [Image from \url {https://cs.umd.edu}.]}{figure.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2.1}A network representation of single cell data and simple summary statistics}{4}{subsubsection.1.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2.2}Degree Distribution}{4}{subsubsection.1.1.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces {\bf  Network of single cells.} We constructed a network from mass cytometry profiling in single cell data. Each node is a single cell and is connected to its 5 nearest neighbors.}}{5}{figure.1.3}}
\newlabel{fig:Cytometry}{{1.3}{5}{{\bf Network of single cells.} We constructed a network from mass cytometry profiling in single cell data. Each node is a single cell and is connected to its 5 nearest neighbors}{figure.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2.3}Centrality}{5}{subsubsection.1.1.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces {\bf  Degree distribution for single cell network.} We visualize the trends in node degree in the single cell network presented in Figure \ref  {fig:Cytometry}. {\bf  A.} We compute a cumulative distribution plot for degree. {\bf  B.} Node degrees can also be visualized with a simple histogram.}}{6}{figure.1.4}}
\newlabel{fig:DegDist}{{1.4}{6}{{\bf Degree distribution for single cell network.} We visualize the trends in node degree in the single cell network presented in Figure \ref {fig:Cytometry}. {\bf A.} We compute a cumulative distribution plot for degree. {\bf B.} Node degrees can also be visualized with a simple histogram}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces {\bf  Centralities on single cell network.} The second order ego network for the highest centrality nodes in the single cell network according to degree, betweenness, and eigenvector in the left, right, and center, respectively.}}{6}{figure.1.5}}
\newlabel{fig:Centrality}{{1.5}{6}{{\bf Centralities on single cell network.} The second order ego network for the highest centrality nodes in the single cell network according to degree, betweenness, and eigenvector in the left, right, and center, respectively}{figure.1.5}{}}
\citation{betzel}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces {\bf  Assortative Community Structure.} Nodes are tightly connected to each other and more sparsely connected to the rest of the network. Each community is outlined with a pink dotted line.}}{8}{figure.1.6}}
\newlabel{fig:Assort}{{1.6}{8}{{\bf Assortative Community Structure.} Nodes are tightly connected to each other and more sparsely connected to the rest of the network. Each community is outlined with a pink dotted line}{figure.1.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Introduction to community detection}{8}{section.1.2}}
\citation{fortu1,fortu2,shaicase}
\citation{newman2006modularity}
\citation{benderCanfield}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Community detection methods}{9}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Quality function maximization with modularity}{9}{subsection.1.3.1}}
\citation{newmangirvan}
\citation{resParam}
\citation{blondel}
\citation{hierarchicalmod}
\citation{browet}
\citation{TwoD}
\citation{originalSBM}
\citation{affil}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces {\bf  A comparison of $k$-means and the Louvain algorithm} A comparison of the results of clustering the single cell dataset by visualizing the original 50 dimensional data with a 2-dimensional projection with tSNE. Points are colored by their cluster membership under $k$-means on the original data (left) and Louvain community detection (right) on the constructed 5 nearest neighbor network.}}{11}{figure.1.7}}
\newlabel{fig:clustering}{{1.7}{11}{{\bf A comparison of $k$-means and the Louvain algorithm} A comparison of the results of clustering the single cell dataset by visualizing the original 50 dimensional data with a 2-dimensional projection with tSNE. Points are colored by their cluster membership under $k$-means on the original data (left) and Louvain community detection (right) on the constructed 5 nearest neighbor network}{figure.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Identifying communities with probabilistic approaches}{11}{subsection.1.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2.1}Probabilistic graphical models for statistical inference}{11}{subsubsection.1.3.2.1}}
\newlabel{pgm}{{1.3.2.1}{11}{Probabilistic graphical models for statistical inference}{subsubsection.1.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces {\bf  Directed Acyclic Graph.} A directed acyclic graph (DAG) is formed based on dependency between random variable and allows for a fully factorized probability distribution.}}{12}{figure.1.8}}
\newlabel{fig:DAG}{{1.8}{12}{{\bf Directed Acyclic Graph.} A directed acyclic graph (DAG) is formed based on dependency between random variable and allows for a fully factorized probability distribution}{figure.1.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces {\bf  SBM Graphical Model.} A graphical model is used to model the dependency between the node-to-community assignments, ${\bf  z}$ and the observed network adjacency matrix, ${\bf  A}$.}}{13}{figure.1.9}}
\newlabel{fig:graphical}{{1.9}{13}{{\bf SBM Graphical Model.} A graphical model is used to model the dependency between the node-to-community assignments, ${\bf z}$ and the observed network adjacency matrix, ${\bf A}$}{figure.1.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2.2}Stochastic Block Model}{13}{subsubsection.1.3.2.2}}
\citation{dudin}
\citation{jakk}
\citation{dudin}
\citation{dudin}
\citation{comp}
\citation{belief}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2.3}Variants to the Classic Stochastic Block Model}{15}{subsubsection.1.3.2.3}}
\citation{aicher,peix}
\citation{vBayes}
\citation{peix}
\citation{mixMember}
\citation{LA}
\citation{mixMember}
\citation{LA}
\citation{mixMember}
\citation{pluralHom}
\citation{bigclam}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2.4}Affiliation model and inference}{17}{subsubsection.1.3.2.4}}
\newlabel{eqAff}{{1.17}{18}{Affiliation model and inference}{equation.1.3.17}{}}
\citation{deepWalk}
\citation{kMean}
\citation{rWalk,gleichpagerank}
\citation{word2Vec}
\citation{node2vec}
\citation{homophily}
\citation{structural}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Deep Learning Approaches}{19}{subsection.1.3.3}}
\citation{Benson}
\citation{laplacian}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Higher order network analysis}{20}{subsection.1.3.4}}
\citation{Benson}
\citation{immuneClock}
\citation{cytof}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Community detection in computational biology}{21}{section.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Immunological profiling to establish a pregnancy immune clock}{21}{subsection.1.4.1}}
\citation{networkMicrobiome}
\citation{moduleMicrobiome}
\citation{girvancommunity}
\citation{Rand}
\citation{hub}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Uncovering differences in microbiome community structure in patients with inflammatory bowel disease}{22}{subsection.1.4.2}}
\citation{nimaFlow}
\citation{FlowSpectral}
\citation{spectral1}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Community detection for analysis of flow cytometry data}{23}{subsection.1.4.3}}
\citation{varIntro}
\citation{larremoreparasite}
\citation{degreeCorrect}
\citation{VI}
\citation{newmanAssort}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Understanding genetic diversity of the malaria parasite genes}{24}{subsection.1.4.4}}
\citation{larremoreparasite}
\citation{phenoGraph}
\citation{intraTumor}
\citation{RWR}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Analysis of high dimensional single cell data for tumor heterogenity}{26}{subsection.1.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}Identification of virulence factor genes related to antibiotic resistance of uropathogenic \emph  {E. coli}}{27}{subsection.1.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Thesis Contribution}{28}{section.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Thesis Statement}{28}{subsection.1.5.1}}
\citation{catala}
\citation{mlsbm1}
\citation{airoldi}
\citation{peng}
\citation{SuperNodeSide}
\citation{gilbert}
\citation{clauset}
\citation{ilouvain}
\citation{cesna}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Summary of the novelty of this work}{29}{subsection.1.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces {\bf  Summarizing the novelty of our 3 developed methods}. For each of the 3 methods we developed, we provide a brief description of what it does, the top 3 most similar approaches, and why our approach is novel.}}{29}{table.1.1}}
\newlabel{Tab11}{{1.1}{29}{{\bf Summarizing the novelty of our 3 developed methods}. For each of the 3 methods we developed, we provide a brief description of what it does, the top 3 most similar approaches, and why our approach is novel}{table.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}Relevant Publications}{29}{subsection.1.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}Software}{30}{subsection.1.5.4}}
\citation{smlsbm}
\citation{ohmNet}
\citation{microbiome}
\citation{kivelamultilayer,boccaletti2014structure,manlioMathFoundations}
\citation{genetic}
\citation{socialnetwork}
\citation{muchamultislice}
\citation{manlioMathFoundations}
\citation{muchamultislice}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}A multilayer stochastic block model}{31}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction to multilayer networks}{31}{section.2.1}}
\citation{domen}
\citation{biclustering}
\citation{cocluster}
\citation{cocluster}
\citation{ugander2013subgraph,motiffinding}
\citation{taxonomy,NONCluster,confusingMesoscopic}
\citation{structurenetwork}
\citation{netensemble}
\citation{porter2009communities,fortunato}
\citation{rombach2014core}
\citation{newmanmodularity}
\citation{abby}
\citation{community,fortunato,leskoveccommunity,clausethierarchy,newmanspectral}
\citation{NONCluster}
\citation{confusingMesoscopic}
\citation{SBM}
\citation{rombach2014core,aicher2015learning}
\citation{abby,guimera2009missing}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Comparing network layers based on community structure}{32}{section.2.2}}
\citation{muchamultislice}
\citation{manlio2}
\citation{airoldi,mlsbm1,barbillon,catala,thiagomlsbm}
\citation{airoldi,mlsbm1,barbillon}
\citation{airoldi}
\citation{Dudin}
\citation{airoldi}
\citation{mlsbm1}
\citation{barbillon}
\citation{airoldi}
\citation{mlsbm1}
\citation{catala}
\citation{thiagomlsbm}
\citation{catala}
\citation{thiagomlsbm}
\citation{domen}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Related work in community detection of multilayer networks}{34}{section.2.3}}
\citation{domen}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}A Summary of Novel Contributions of sMLSBM}{36}{section.2.4}}
\newlabel{goals}{{2.4}{37}{A Summary of Novel Contributions of sMLSBM}{section.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces {\bf  Objective of strata multilayer stochastic block model (sMLSBM)}. Each of the $L=9$ networks here represents a layer in a multilayer network. Every network layer has $N=36$ nodes that are consistent across all layers. There are $S=3$ strata as indicated by the three rows and the colors of nodes. Clearly, network layers within a stratum exhibit strong similarities in community structure. That is, although each layer follows an SBM with $K=3$ communities, the SBM parameters are identical for layers within a strata but differ between layers in different strata. We would like to partition the layers into their appropriate strata and learn their associated SBM parameters, $\pi ^s$ and $Z^s$.}}{37}{figure.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}sMLSBM Model Definition}{37}{section.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Inference for learning model parameters of sMLSBM}{38}{section.2.6}}
\newlabel{eq1}{{2.1}{38}{Inference for learning model parameters of sMLSBM}{equation.2.6.1}{}}
\citation{Dudin}
\citation{gap}
\citation{dudin}
\citation{airoldi}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces {\bf  Schematic illustration of our algorithm}: Our algorithm for fitting an sMLSBM is broken up into two phases: an initialization phase to cluster layers into strata, and an iterative phase that allows learning of node-to-community and layer-to-strata assignments.}}{40}{figure.2.2}}
\newlabel{fig:Schematic}{{2.2}{40}{{\bf Schematic illustration of our algorithm}: Our algorithm for fitting an sMLSBM is broken up into two phases: an initialization phase to cluster layers into strata, and an iterative phase that allows learning of node-to-community and layer-to-strata assignments}{figure.2.2}{}}
\citation{dempster}
\citation{dudin}
\citation{airoldi,barbillon,dudin}
\citation{Dudin}
\citation{commdeccompare}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Synthetic Examples}{44}{section.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Comparison of sMLSBM to other SBM Approaches}{44}{subsection.2.7.1}}
\newlabel{sec:SBM1}{{2.7.1}{44}{Comparison of sMLSBM to other SBM Approaches}{subsection.2.7.1}{}}
\newlabel{fig:SynExp1}{{2.7.1}{45}{Comparison of sMLSBM to other SBM Approaches}{subsection.2.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces {\bf  \noindent Synthetic experiment comparing sMLSBM to other SBMs.} {\bf  A}.\nobreakspace  {}We specified a model with $S=3$ strata and $L=10$ layers per stratum. A representative layer from each stratum is plotted. Note that nodes in all networks are colored according to their community membership in stratum 1. Each network has $N=128$ nodes, $K=4$ communities and mean degree, $c=20$. The $p_{in}^s$ parameters for $s=1,$ $2$ and 3 are 0.6, 0.4 and 0.25, respectively. Corresponding values of $p_{out}^s$ were selected to maintain the desired expected mean degree, c=20. {\bf  B}. We fit 3 types of models to the 30 network layers: i) single SBM: fitting a single SBM to all of the layers; ii) single-Layer SBM: fitting an individual SBM to each layer; and iii) sMLSBM: identifying strata and fitting an SBMs for each strata. Each model yields an estimate $\overline  {{\boldsymbol  \pi }^{s_l}}$ for the true SBM of each layer $l$, which is denoted ${{\boldsymbol  \pi }}^{l}$. Here $s_l$ denotes the inferred strata for layer $l$. On the vertical axis we plot the mean $\ell $2 norm error $||\text  {vec}({\boldsymbol  \pi ^{l})}-\text  {vec}(\overline  {{\boldsymbol  \pi }^{s_{l}}})||_{2}$. {\bf  C}. For each of the three models, we computed the normalized mutual information (NMI) between the true node-to-community assignments ${{\bf  z}^{l}}$ and the inferred values $\overline  {{\bf  z}^{s_l}}$.}}{45}{figure.2.3}}
\citation{decelle2011inference}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Synthetic Experiment with Two Strata}{46}{subsection.2.7.2}}
\newlabel{sec:2strata}{{2.7.2}{46}{Synthetic Experiment with Two Strata}{subsection.2.7.2}{}}
\citation{microbiome}
\citation{microbeco}
\citation{sparcc}
\citation{sparcc}
\citation{sparcc}
\newlabel{fig:saray}{{2.7.2}{48}{Synthetic Experiment with Two Strata}{subsection.2.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  {\bf  Synthetic experiment with two strata.} We conducted numerical experiments with multilayer networks with $N=128$ nodes, mean degree $c=16$, $S=2$ strata and $K^1=K^2=4$ communities. The networks contained either $L=10$ (left column) or $L=100$ layers (right column), which were divided equally into the two strata. For stratum 1, we fixed the quantity $N(p_{{in}}^{1}-p_{{out}}^{1})=10$, which fully specifies $(p_{{in}}^{1},p_{{out}}^{1})$ since setting $c=16$ also constrains these parameters. In contrast, we vary $N(p_{{in}}^{2}-p_{{out}}^{2})$. {\bf  A}. As a function of $N(p_{{in}}^{2}-p_{{out}}^{2})$, we plot the mean NMI to interpret the ability of sMLSBM to recover the true layer-to-strata assignments. We compare the performance of sMLSBM (purple curve) to generic $k$-means clustering (green symbols) of adjacency matrices. {\bf  B.} We plot the mean number of iterations (NOI) required for Phase II of our algorithm to converge. {\bf  C.} Finally, we measure the quality of node-to-community assignment results by plotting the mean NMI between the true node-to-community assignments and those inferred with sMLSBM in stratum 1 (red symbols) and stratum 2 (blue symbols).}}{48}{figure.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Human Microbiome Project Example}{49}{section.2.8}}
\citation{domen}
\citation{dingcluster}
\citation{dingcluster}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Comparison of sMLSBM to multilayer network reducibility}{50}{subsection.2.8.1}}
\citation{sparcc}
\citation{domen}
\citation{sparcc}
\citation{domen}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces {\bf  Comparison of sMLSBM on the OTU interaction networks \citep  {sparcc} for each of the body sites to a reducibility hierarchy \citep  {domen}.} As described in the text, we consider a multiplex network with $L=18$ layers and $N=213$ nodes, which we group here into $S=6$ strata, while the dendrogram was generated by the method employed as the precursor to the reducibility framework. Colored boxes around the leaves of the dendrogram designate the body site to strata assignments obtained with sMLSBM.}}{51}{figure.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Generating samples from the fitted sMLSBM}{51}{subsection.2.8.2}}
\citation{domen}
\citation{taylor2015enhanced}
\citation{domen}
\citation{domen}
\citation{weightSBM}
\citation{sbmdirect}
\citation{degreecorrectSBM}
\citation{antagonism}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Concluding remarks for sMLSBM}{52}{section.2.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces {\bf  Visualization of Strata in SparCC Networks.} We visualize the adjacency matrices for SparCC networks that encode microbiome interactions at body sites. In each panel, a colored dot at position $(i,j)$ indicates the existence of an edge $(i,j)$ in the corresponding network layer. The four rows correspond to four different strata. In column 1, we show a sample network generated from the SBM parameters, $\overline  {{\boldsymbol  \pi }^{s}}$ and $\overline  {{\bf  Z}^{s}}$, that we inferred for that stratum. In Columns 2 and 3, we show SparCC networks from that particular stratum. Note the strong similarity across each row.}}{53}{figure.2.6}}
\newlabel{sampleNet}{{2.6}{53}{{\bf Visualization of Strata in SparCC Networks.} We visualize the adjacency matrices for SparCC networks that encode microbiome interactions at body sites. In each panel, a colored dot at position $(i,j)$ indicates the existence of an edge $(i,j)$ in the corresponding network layer. The four rows correspond to four different strata. In column 1, we show a sample network generated from the SBM parameters, $\overline {{\boldsymbol \pi }^{s}}$ and $\overline {{\bf Z}^{s}}$, that we inferred for that stratum. In Columns 2 and 3, we show SparCC networks from that particular stratum. Note the strong similarity across each row}{figure.2.6}{}}
\citation{taylor2015enhanced}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Detectability in a single stratum}{54}{section.2.10}}
\citation{detect20,detect21,detect22,detect23,detect24,detect25}
\citation{detectDegreeHetero}
\citation{peixotoHierarchAttribute,HierarchAttl}
\citation{detectTemporal}
\citation{detect23,detect24}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.1}Investigating detectability in a multilayer network}{55}{subsection.2.10.1}}
\citation{detect23}
\citation{detect24}
\citation{detect38,detect39}
\citation{detect24,peixotoHierarchAttribute,HierarchAttl}
\citation{newmangirvan}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.2}Studying detectability in two block networks}{56}{subsection.2.10.2}}
\newlabel{detectEquation}{{2.14}{56}{Studying detectability in two block networks}{equation.2.10.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.3}Using random matrix theory to study detectability}{56}{subsection.2.10.3}}
\citation{taylor2015enhanced}
\citation{taylor2015enhanced}
\citation{airoldi}
\citation{detect25}
\citation{smlsbm}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.4}Results}{58}{subsection.2.10.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.5}Conclusion}{58}{subsection.2.10.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces {\bf  Effects of layer aggregation on detectability.} Layer aggregation enhances the detectability of community structure. (a),(b). We plot the detectability limit $\Delta ^{*}$ versus mean edge probability $\rho $ for a single network layer (red dot-dashed curves), the aggregate network obtained by summation (blue dashed curves), and aggregate networks obtained by thresholding this summation at $\mathaccentV {tilde}07E{L} \in \{1,2,3,4\}$ (solid curves). Gold circles and cyan squares highlight $\mathaccentV {tilde}07E{L}=L$ and $\mathaccentV {tilde}07E{L}=1$, which we refer to as AND and OR networks, respectively. Results are shown for $N=10^{4}$ nodes with (a) $L=4$ and (b) $L=16$ layers. (c) For $L=4$, we show $\Delta ^{*}$ versus $\rho $ for the optimal threshold $\mathaccentV {tilde}07E{L}=\ceil  *{\rho L}$ (orange triangles), which lies on the solution curves for $\mathaccentV {tilde}07E{L} \in \{1,\dots  ,L\}$ (solid curves). (d) We show $\Delta ^{*}$ for $\mathaccentV {tilde}07E{L}=\ceil  *{\rho L}$ with $L \in \{4,16\}$. These piecewise-continuous solutions collapse onto the asymptotic solution $\delta _{\text  {asym}}^{*}$ (black curve) as $L$ increases. In panels (c), (d), we additionally plot $\delta ^{*}$ for the summation network (blue dashed curves). }}{59}{figure.2.7}}
\newlabel{Detect}{{2.7}{59}{{\bf Effects of layer aggregation on detectability.} Layer aggregation enhances the detectability of community structure. (a),(b). We plot the detectability limit $\Delta ^{*}$ versus mean edge probability $\rho $ for a single network layer (red dot-dashed curves), the aggregate network obtained by summation (blue dashed curves), and aggregate networks obtained by thresholding this summation at $\tilde {L} \in \{1,2,3,4\}$ (solid curves). Gold circles and cyan squares highlight $\tilde {L}=L$ and $\tilde {L}=1$, which we refer to as AND and OR networks, respectively. Results are shown for $N=10^{4}$ nodes with (a) $L=4$ and (b) $L=16$ layers. (c) For $L=4$, we show $\Delta ^{*}$ versus $\rho $ for the optimal threshold $\tilde {L}=\ceil *{\rho L}$ (orange triangles), which lies on the solution curves for $\tilde {L} \in \{1,\dots ,L\}$ (solid curves). (d) We show $\Delta ^{*}$ for $\tilde {L}=\ceil *{\rho L}$ with $L \in \{4,16\}$. These piecewise-continuous solutions collapse onto the asymptotic solution $\delta _{\text {asym}}^{*}$ (black curve) as $L$ increases. In panels (c), (d), we additionally plot $\delta ^{*}$ for the summation network (blue dashed curves)}{figure.2.7}{}}
\citation{https://snap.stanford.edu/data/}
\citation{compressing}
\citation{browet}
\citation{slic}
\citation{slic}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Network compression for community detection with super nodes}{61}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Super pixel pre-processing of images}{61}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces {\bf  Superpixel pre-processing of an image.} An image can be represented by a $1147 \times 1147$ grid of pixels (left). Representing the image with 600 super pixels (right), reduces the size of the image and hence the segmentation problem is to partition the set of 600 super pixels. }}{62}{figure.3.1}}
\newlabel{fig:superPix}{{3.1}{62}{{\bf Superpixel pre-processing of an image.} An image can be represented by a $1147 \times 1147$ grid of pixels (left). Representing the image with 600 super pixels (right), reduces the size of the image and hence the segmentation problem is to partition the set of 600 super pixels}{figure.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Super node pre-processing for networks}{62}{section.3.2}}
\citation{danon}
\citation{jureTruth}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Problem Formulation}{63}{subsection.3.2.1}}
\newlabel{UnderSeg}{{3.1}{63}{Problem Formulation}{equation.3.2.1}{}}
\newlabel{NMI}{{3.2}{63}{Problem Formulation}{equation.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}An opportunity for super nodes in community detection}{63}{subsection.3.2.2}}
\citation{supergenomic,SuperNodeSide,gilbert,peng}
\citation{SuperNodeSide}
\citation{peng}
\citation{SuperNodeSide}
\citation{supergenomic}
\citation{supergenomic}
\citation{SuperNodeSide}
\citation{gilbert}
\citation{peng}
\citation{gilbert}
\citation{peng}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Background}{64}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Related Work}{64}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Validation metrics for a quality super node representation}{65}{subsection.3.3.2}}
\citation{blondel}
\citation{tiagosbm}
\citation{tiagosbm}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces {\bf  Defining super nodes}. To define the super node representation of a network, we select $S$ seeds and agglomerate local regions around them to create super nodes. This then leads to a new network with weighted edges between the $S$ super nodes upon which community detection can be more efficiently applied.}}{67}{figure.3.2}}
\newlabel{Fig1}{{3.2}{67}{{\bf Defining super nodes}. To define the super node representation of a network, we select $S$ seeds and agglomerate local regions around them to create super nodes. This then leads to a new network with weighted edges between the $S$ super nodes upon which community detection can be more efficiently applied}{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2.1}Objectively Comparing Partitions on Possibly Different Scales}{67}{subsubsection.3.3.2.1}}
\citation{jungirie,kempe}
\citation{CoreHD}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Methods}{68}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Defining seeds}{68}{subsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces {\bf  Choosing seeds in a synthetic network}. The identification of 20 seeds with the CoreHD algorithm in a network generated from a stochastic block model with 8 communities. Seeds (black nodes) are well distributed across communities.}}{69}{figure.3.3}}
\newlabel{Synth}{{3.3}{69}{{\bf Choosing seeds in a synthetic network}. The identification of 20 seeds with the CoreHD algorithm in a network generated from a stochastic block model with 8 communities. Seeds (black nodes) are well distributed across communities}{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Grow Super Nodes Around Seeds}{69}{subsection.3.4.2}}
\citation{snapdata}
\citation{newmandata}
\citation{traaglouvain}
\citation{blondel}
\citation{tiagoskewed}
\citation{tiagosbm}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Network data characteristics.}}{70}{table.3.1}}
\newlabel{table:dataset}{{3.1}{70}{Network data characteristics}{table.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Create Network of Super Nodes}{70}{subsection.3.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Results}{70}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Overview of experiments}{71}{subsection.3.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces {\bf  Schematic of possible partition comparisons.} We outline the types of possible comparisons between partitions generated according to various combinations of network representation and community detection method. According to these comparison rules, we compute normalized mutual information (NMI) between all pairs of networks satisfying the comparison criteria. The colored circles in the schematic represent a single partition generated under the corresponding network representation and community detection algorithm combination. Circles are colored (in each column) by each of the four possible representation/community detection method combinations. In {\bf  A-C}, we outline the types of comparisons we perform in subsequent figures. {\bf  A.} To compare the usefulness of the super node representation in identifying communities retrieved using the full network, we compare pairs of networks with different representations under the same community detection algorithm. {\bf  B.} Due to the stochastic nature of both the Louvain algorithm and SBM fitting, this comparison seeks to quantify partitions generated under the same network representation and method. {\bf  C.} Finally, we consider pairs of partitions generated under the same network representation and different community detection algorithms. }}{72}{figure.3.4}}
\newlabel{concept}{{3.4}{72}{{\bf Schematic of possible partition comparisons.} We outline the types of possible comparisons between partitions generated according to various combinations of network representation and community detection method. According to these comparison rules, we compute normalized mutual information (NMI) between all pairs of networks satisfying the comparison criteria. The colored circles in the schematic represent a single partition generated under the corresponding network representation and community detection algorithm combination. Circles are colored (in each column) by each of the four possible representation/community detection method combinations. In {\bf A-C}, we outline the types of comparisons we perform in subsequent figures. {\bf A.} To compare the usefulness of the super node representation in identifying communities retrieved using the full network, we compare pairs of networks with different representations under the same community detection algorithm. {\bf B.} Due to the stochastic nature of both the Louvain algorithm and SBM fitting, this comparison seeks to quantify partitions generated under the same network representation and method. {\bf C.} Finally, we consider pairs of partitions generated under the same network representation and different community detection algorithms}{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Normalized mutual information and under segmentation error}{72}{subsection.3.5.2}}
\citation{tiagosbm}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Run time Analysis}{73}{subsection.3.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces {\bf  Super Node Quality.} We computed normalized mutual information ({\bf  A.}) and under segmentation error ({\bf  B.}) for networks represented by between 100 and 600 super nodes. Line type and color indicate the community detection algorithm applied (Louvain algorithm or SBM fitting). Each curve indicates the mean across 5 super node representations. The shaded area shows standard deviation. {\bf  A.} Normalized mutual information between the full and super node representations of networks [i.e. NMI$({\bf  z}^{Full},{\bf  z}^{SN})$]. A network representation with more super nodes. generally increases the NMI between full network and super node network representations. Horizontal lines indicate the mean pairwise NMI between 10 runs of the Louvain algorithm and SBM result on the full network (pink and gold, respectively). Given the high variability between multiple runs of the same algorithm on the full network, adding more super nodes can only improve the NMI between the full and super node representation to the observed level of similarity observed between algorithm runs. {\bf  B.} The log under segmentation error for super node representations. Defining a super node representation with more super nodes generally decreases the under segmentation error. }}{74}{figure.3.5}}
\newlabel{FigQuality}{{3.5}{74}{{\bf Super Node Quality.} We computed normalized mutual information ({\bf A.}) and under segmentation error ({\bf B.}) for networks represented by between 100 and 600 super nodes. Line type and color indicate the community detection algorithm applied (Louvain algorithm or SBM fitting). Each curve indicates the mean across 5 super node representations. The shaded area shows standard deviation. {\bf A.} Normalized mutual information between the full and super node representations of networks [i.e. NMI$({\bf z}^{Full},{\bf z}^{SN})$]. A network representation with more super nodes. generally increases the NMI between full network and super node network representations. Horizontal lines indicate the mean pairwise NMI between 10 runs of the Louvain algorithm and SBM result on the full network (pink and gold, respectively). Given the high variability between multiple runs of the same algorithm on the full network, adding more super nodes can only improve the NMI between the full and super node representation to the observed level of similarity observed between algorithm runs. {\bf B.} The log under segmentation error for super node representations. Defining a super node representation with more super nodes generally decreases the under segmentation error}{figure.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces {\bf  Runtimes}. We compare community detection runtimes (in seconds) with the Louvain algorithm and by fitting an SBM on the full networks and super node representations for the 9 data sets. {\bf  (A.)} Louvain on the full network. {\bf  (B.)} Louvain on the super nodes. {\bf  (C.)} SBM on the full network. {\bf  (D.)} SBM on the super nodes.}}{75}{figure.3.6}}
\newlabel{RT}{{3.6}{75}{{\bf Runtimes}. We compare community detection runtimes (in seconds) with the Louvain algorithm and by fitting an SBM on the full networks and super node representations for the 9 data sets. {\bf (A.)} Louvain on the full network. {\bf (B.)} Louvain on the super nodes. {\bf (C.)} SBM on the full network. {\bf (D.)} SBM on the super nodes}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Quantifying variability across algorithm runs}{75}{subsection.3.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces {\bf  Quantifying partition variability.} For each of the 9 networks, we obtained 10 different partitions by the Louvain algorithm and 10 different SBM fits under the default ({\bf  A.}) and matched settings ({\bf  B.}). To assess the similarity between partitions within and between a community detection algorithm in networks under the the super node representation, we computed pairwise normalized mutual information (NMI) as a function of the number of super nodes. The pink and blue curves show the mean pairwise normalized mutual information between all pairs of 10 partitions under Louvain and SBM fitting, respectively. The gold curves compare pairs of partitions under different methods. Shaded area denotes standard deviation. Horizontal lines indicates the mean pairwise NMI between partitions under the full network representation for within Louvain and SBM partition comparison (pink and blue, respectively) and between Louvain and SBM partition comparison (gold). Overall, the super node representation is useful for reducing the disparity between the partitions obtained under different methods.}}{76}{figure.3.7}}
\newlabel{VAR}{{3.7}{76}{{\bf Quantifying partition variability.} For each of the 9 networks, we obtained 10 different partitions by the Louvain algorithm and 10 different SBM fits under the default ({\bf A.}) and matched settings ({\bf B.}). To assess the similarity between partitions within and between a community detection algorithm in networks under the the super node representation, we computed pairwise normalized mutual information (NMI) as a function of the number of super nodes. The pink and blue curves show the mean pairwise normalized mutual information between all pairs of 10 partitions under Louvain and SBM fitting, respectively. The gold curves compare pairs of partitions under different methods. Shaded area denotes standard deviation. Horizontal lines indicates the mean pairwise NMI between partitions under the full network representation for within Louvain and SBM partition comparison (pink and blue, respectively) and between Louvain and SBM partition comparison (gold). Overall, the super node representation is useful for reducing the disparity between the partitions obtained under different methods}{figure.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Neighborhood agreement}{76}{subsection.3.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces {\bf  Agreement of community assignments with local connectivity}. We study how consistent partitions are within local neighborhood regions of the network by examining how well a node's neighbors (for various order neighborhoods) can be used to predict its community assignment, under some community partition ${\bf  z}$. For each community in a partition, we give a binary prediction of whether a node is assigned to that community, based on probabilities we compute for a node from its neighbors. Sweeping the parameter $p$ that sets the probability required for a node to be assigned to a community, we compute ROC curves for each community and report the minimum AUC value observed. Panels {\bf  A-D} show minimum AUC values observed as a function of neighborhood order for communities obtained from the full networks and super node representations by Louvain and by SBM. Line color indicates network and line type indicates communities obtained from the matched and default parameters used by the algorithms on the full networks. Panels {\bf  E-H} visualize the communities obtained in the As22 data on the full network (default parameters) and super node representation (SN) under Louvain and SBM, with node colors indicating community memberships. }}{78}{figure.3.8}}
\newlabel{Viz}{{3.8}{78}{{\bf Agreement of community assignments with local connectivity}. We study how consistent partitions are within local neighborhood regions of the network by examining how well a node's neighbors (for various order neighborhoods) can be used to predict its community assignment, under some community partition ${\bf z}$. For each community in a partition, we give a binary prediction of whether a node is assigned to that community, based on probabilities we compute for a node from its neighbors. Sweeping the parameter $p$ that sets the probability required for a node to be assigned to a community, we compute ROC curves for each community and report the minimum AUC value observed. Panels {\bf A-D} show minimum AUC values observed as a function of neighborhood order for communities obtained from the full networks and super node representations by Louvain and by SBM. Line color indicates network and line type indicates communities obtained from the matched and default parameters used by the algorithms on the full networks. Panels {\bf E-H} visualize the communities obtained in the As22 data on the full network (default parameters) and super node representation (SN) under Louvain and SBM, with node colors indicating community memberships}{figure.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Conclusion and Future Work}{79}{section.3.6}}
\citation{hric,peel2017ground,jureTruth}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}An attributed stochastic block model}{80}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Motivation for studying attributed networks}{80}{section.4.1}}
\citation{cesna,clauset,ilouvain,hric,peel2017ground}
\citation{ilouvain}
\citation{blondel}
\citation{clauset,hric,peel2017ground,cesna}
\citation{cesna}
\citation{originalSBM}
\citation{clauset}
\citation{hric}
\citation{peel2017ground}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces {\bf  Modeling community membership in terms of attributes and connectivity}. Node-to-community assignments specified by ${\bf  Z}$ are determined in terms of adjacency matrix information, ${\bf  A}$ and attribute matrix information, ${\bf  X}$. ${\bf  A}$ and ${\bf  X}$ are assumed by be generated from a stochastic block model and a mixture of multivariate Gaussian distributions, parameterized by ${\boldsymbol  \theta }$ and ${\boldsymbol  \Psi }$, respectively. }}{83}{figure.4.1}}
\newlabel{fig:graphical_model}{{4.1}{83}{{\bf Modeling community membership in terms of attributes and connectivity}. Node-to-community assignments specified by ${\bf Z}$ are determined in terms of adjacency matrix information, ${\bf A}$ and attribute matrix information, ${\bf X}$. ${\bf A}$ and ${\bf X}$ are assumed by be generated from a stochastic block model and a mixture of multivariate Gaussian distributions, parameterized by ${\boldsymbol \theta }$ and ${\boldsymbol \Psi }$, respectively}{figure.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}An Attributed Stochastic Block Model}{83}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Objective}{83}{subsection.4.2.1}}
\newlabel{eqn:likelihood_decomposition}{{4.1}{83}{Objective}{equation.4.2.1}{}}
\citation{dempster}
\newlabel{post}{{4.3}{84}{Objective}{equation.4.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Attribute Likelihood}{84}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Adjacency Matrix Likelihood}{84}{subsection.4.2.3}}
\citation{dudin}
\citation{blondel}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Inference}{85}{subsection.4.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Initialization}{86}{subsection.4.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Synthetic Data Results}{86}{section.4.3}}
\citation{commdeccompare}
\citation{decelle2011inference,taylor2015enhanced}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces {\bf  Synthetic Example.} We generated a synthetic network with $N=200$ nodes, $K=4$ communities and an 8-dimensional multivariate Gaussian for each community. {\bf  A.} A visualization of the adjacency matrix for this network where a black dot indicates an edge. We observe that there is an assortative block structure (blocks on the diagonal), but there are also many 'noisy' edges between communities making the true community structure with only a stochastic block model a bit harder to detect. {\bf  B.} We performed PCA on the $N \times p$ dimensional attribute array and plotted each of the $N$ nodes in two dimensions. Points are colored by their true community assignments, ${\bf  z}$. Clustering the nodes according to only connectivity, only attributes, and with the attributed SBM, we quantified the partition accuracy with normalized mutual information. This gave results $\text  {NMI}({\bf  z},\{{\bf  z}^{\text  {connectivity}}, {\bf  z}^{\text  {attributes}},{\bf  z}^{\text  {attribute sbm}}\})=\{0.65,0.68,0.83\}$.}}{87}{figure.4.2}}
\newlabel{fig:AttFig2}{{4.2}{87}{{\bf Synthetic Example.} We generated a synthetic network with $N=200$ nodes, $K=4$ communities and an 8-dimensional multivariate Gaussian for each community. {\bf A.} A visualization of the adjacency matrix for this network where a black dot indicates an edge. We observe that there is an assortative block structure (blocks on the diagonal), but there are also many 'noisy' edges between communities making the true community structure with only a stochastic block model a bit harder to detect. {\bf B.} We performed PCA on the $N \times p$ dimensional attribute array and plotted each of the $N$ nodes in two dimensions. Points are colored by their true community assignments, ${\bf z}$. Clustering the nodes according to only connectivity, only attributes, and with the attributed SBM, we quantified the partition accuracy with normalized mutual information. This gave results $\text {NMI}({\bf z},\{{\bf z}^{\text {connectivity}}, {\bf z}^{\text {attributes}},{\bf z}^{\text {attribute sbm}}\})=\{0.65,0.68,0.83\}$}{figure.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Detectability analysis}{88}{subsection.4.3.1}}
\citation{linkPredReview}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces {\bf  Detectability Analysis in Synthetic Example.} To understand how attribute information can be combined with connectivity to assign nodes to communities accurately, we generated synthetic networks for within-probabilities of $p_{in}$ between 0.05 and 0.3 with corresponding $p_{out}$ or between-community probabilities such that the mean degree of the network was 20. For each of these synthetic networks, we used the attributes from the analysis in figure 2 to fit the attributed SBM. Here, we plot the correctness of the node-to-community assignment with normalized mutual information using the partition obtained from regular SBM (blue) and the partition under the attributed SBM model fit (pink). For each combination of $p_{in}$ and $p_{out}$, we generated 10 networks and hence the bands around the points denote standard deviation. Incorporating attributes with the attributes stochastic block model shifts the detectability limit slightly to the left. }}{89}{figure.4.3}}
\newlabel{Att:Detect}{{4.3}{89}{{\bf Detectability Analysis in Synthetic Example.} To understand how attribute information can be combined with connectivity to assign nodes to communities accurately, we generated synthetic networks for within-probabilities of $p_{in}$ between 0.05 and 0.3 with corresponding $p_{out}$ or between-community probabilities such that the mean degree of the network was 20. For each of these synthetic networks, we used the attributes from the analysis in figure 2 to fit the attributed SBM. Here, we plot the correctness of the node-to-community assignment with normalized mutual information using the partition obtained from regular SBM (blue) and the partition under the attributed SBM model fit (pink). For each combination of $p_{in}$ and $p_{out}$, we generated 10 networks and hence the bands around the points denote standard deviation. Incorporating attributes with the attributes stochastic block model shifts the detectability limit slightly to the left}{figure.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Using the fitted attributed SBM for link prediction and collaborative filtering}{89}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Link Prediction Methods}{89}{subsection.4.4.1}}
\citation{linkComm}
\citation{collabFilterReview}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Collaborative Filtering Methods}{90}{subsection.4.4.2}}
\citation{collabComm}
\citation{microbiomedata}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Applications in Biological Networks}{92}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Microbiome Subject Similarity Results}{92}{subsection.4.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.1}Motivation}{92}{subsubsection.4.5.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.2}Pre-Processing}{92}{subsubsection.4.5.1.2}}
\citation{dudin}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.3}Constructing Node Attributes}{93}{subsubsection.4.5.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.4}Link Prediction Experiments}{93}{subsubsection.4.5.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.5}Collaborative Filtering Experiments}{93}{subsubsection.4.5.1.5}}
\citation{bonacci}
\citation{bonacci}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces {\bf  Microbiome subject similarity network:} A visualization of the 121 node microbiome subject similarity network with nodes colored by the partition using the classic ({\bf  A.}) and attributed ({\bf  B.}) stochastic block model. {\bf  A.} Fitting the classic stochastic block model to the network, 7 communities were identified. {\bf  B.} Fitting the attributed stochastic block model to the network with the attributes being the first 5 principle components of each subject's OTU count vector (metagenomic profile), 6 communities were identified. Incorporating attributes in inferring this partition removed some of the noise in the partition on the network, specifically in the mixed purple community in the left of {\bf  A.}}}{94}{figure.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Protein Interaction Network Results}{94}{subsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces {\bf  Link Prediction on the microbiome subject similarity network:} The results for link prediction on the microbiome subject similarity network for the attributed SBM, Jaccard, Adamic-Adar and preferential attachment methods. The corresponding AUC values for these methods, respectively are, 0.71, 0.69, 0.69, and 0.62.}}{95}{figure.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces {\bf  Collaborative Filtering Accuracy in Microbiome Subject Similarity Network}: For each of the 121 nodes, we fit a model to the remaining 120 node network and given the node's closest neighbors (based on network connectivity) sought to predict its 5-dimensional attribute vector. The reported error is the relative error $\mathcal  {E}$ between the difference between the true attribute vector (${\bf  x}_{i}$) and its predicted attribute vector (${\mathaccentV {hat}05E{\bf  x}}_{i}$). The mean error in ${\bf  x}_{i}$ is 0.21, as opposed to the neighbor average and weighted neighbor averages, having errors of 0.26 and 0.27, respectively. }}{96}{figure.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces {\bf  Protein interaction network.} We visualize the 82 node protein interaction network under the classic stochastic block model {\bf  A.} and the attributed stochastic block model {\bf  B.} In both networks, nodes are colored by their community assignment and the node shape indicates whether the modification status increased (square) or decreased. {\bf  A.} Nodes colored according to the community partition under the stochastic block model. Nodes are assigned to one of five communities. {\bf  B.} Nodes are colored to the community partition under one of nine communities.}}{96}{figure.4.7}}
\citation{dudin}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2.1}Data Pre-Processing}{97}{subsubsection.4.5.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2.2}Constructing Node Attributes}{97}{subsubsection.4.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces {\bf  Community entropies in the protein interaction network.} We studied the entropy of the 2 class and 6 class classifications of the nodes in {\bf  A.} and {\bf  B.}, respectively under the classic SBM (black) and attributed SBM (purple) partitions. For ${\bf  A.-B.}$ the horizontal axis denotes the community index for the particular partition. Nodes belonged to 1 of 5 communities under the classic SBM and belong to 1 of 9 communities with the attributed SBM. Incorporating attributes under both classifications succeeds in breaking up a high entropy community (5) from the classic SBM partition to lower entropy communities in the attributed SBM partition. }}{98}{figure.4.8}}
\newlabel{entropyFig}{{4.8}{98}{{\bf Community entropies in the protein interaction network.} We studied the entropy of the 2 class and 6 class classifications of the nodes in {\bf A.} and {\bf B.}, respectively under the classic SBM (black) and attributed SBM (purple) partitions. For ${\bf A.-B.}$ the horizontal axis denotes the community index for the particular partition. Nodes belonged to 1 of 5 communities under the classic SBM and belong to 1 of 9 communities with the attributed SBM. Incorporating attributes under both classifications succeeds in breaking up a high entropy community (5) from the classic SBM partition to lower entropy communities in the attributed SBM partition}{figure.4.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2.3}Link prediction experiments}{98}{subsubsection.4.5.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces {\bf  Link Prediction in the protein interaction network}. Performing link prediction using the attributed SBM, Jaccard, Adamic Adar, and preferential attachment. The corresponding AUC curves for these methods were 0.61, 0.58, 0.58, and 0.51, respectively.}}{99}{figure.4.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2.4}Collaborative filtering experiments}{99}{subsubsection.4.5.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces {\bf  Collaborative filtering in the protein interaction network}. For each of the 82 nodes, we fit a model to the remaining 81 node network and given the node's closest neighbors (based on network connectivity) sought to predict its 6-dimensional attribute vector. The reported error is the relative error $\mathcal  {E}$ between the difference between the true attribute vector (${\bf  x}_{i}$) and its predicted attribute vector (${\mathaccentV {hat}05E{\bf  x}}_{i}$). The mean error in ${\bf  x}_{i}$ using the attributed SBM is 0.21, as opposed to the neighbor average error where it is 0.48. }}{100}{figure.4.10}}
\newlabel{collabprotein}{{4.10}{100}{{\bf Collaborative filtering in the protein interaction network}. For each of the 82 nodes, we fit a model to the remaining 81 node network and given the node's closest neighbors (based on network connectivity) sought to predict its 6-dimensional attribute vector. The reported error is the relative error $\mathcal {E}$ between the difference between the true attribute vector (${\bf x}_{i}$) and its predicted attribute vector (${\hat {\bf x}}_{i}$). The mean error in ${\bf x}_{i}$ using the attributed SBM is 0.21, as opposed to the neighbor average error where it is 0.48}{figure.4.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Conclusion and Future Work}{100}{section.4.6}}
\citation{walsh2017}
\citation{boon}
\citation{mutualism}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}A network approach to understanding microbiome disruption in response to acute lung injury}{102}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Background and Motivation}{102}{section.5.1}}
\citation{miSeq}
\citation{your}
\citation{sparcc}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Data Background}{103}{subsection.5.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Network Analysis Methods}{103}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Creating Networks with SparCC}{103}{subsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces {\bf  Microbial co-occurence networks for each patient cohort}. We constructed networks with SparCC in the ALI and non-ALI cohort networks (left and right, respectively). Four communities were identified in each network. Nodes are colored by their community assignment.}}{104}{figure.5.1}}
\newlabel{alinet}{{5.1}{104}{{\bf Microbial co-occurence networks for each patient cohort}. We constructed networks with SparCC in the ALI and non-ALI cohort networks (left and right, respectively). Four communities were identified in each network. Nodes are colored by their community assignment}{figure.5.1}{}}
\citation{picrust}
\citation{gini}
\newlabel{my-label}{{5.3.1}{105}{Community overlap between network}{subsection.5.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces {\bf  Comparing Networks in Each Patient Cohort}. We compare the OTUs in each pair of communities in the ALI and No ALI cohort networks. Large overlaps are denoted by pink shading in the table.}}{105}{table.5.1}}
\newlabel{Tab5}{{5.1}{105}{{\bf Comparing Networks in Each Patient Cohort}. We compare the OTUs in each pair of communities in the ALI and No ALI cohort networks. Large overlaps are denoted by pink shading in the table}{table.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Results}{105}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Community overlap between network}{105}{subsection.5.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Evaluating functional differences}{105}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Classifying each community according to predicted function}{106}{subsection.5.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Discussion}{106}{section.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces {\bf  Predictive functions for community classification}. We used a set of 328 filtered functions to predict OTU-to-community assignment in the ALI and No ALI network (left and right, respectively). Biological features with more discriminative ability in classification from the random forest classifier are ranked higher on the list.}}{107}{figure.5.2}}
\newlabel{Function}{{5.2}{107}{{\bf Predictive functions for community classification}. We used a set of 328 filtered functions to predict OTU-to-community assignment in the ALI and No ALI network (left and right, respectively). Biological features with more discriminative ability in classification from the random forest classifier are ranked higher on the list}{figure.5.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{108}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}sMLSBM}{108}{section.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Recap}{108}{subsection.6.1.1}}
\citation{peelChange}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Future Work}{109}{subsection.6.1.2}}
\citation{SuperNodeSide,supergenomic}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Super Nodes}{110}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Recap}{110}{subsection.6.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Future Work}{110}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Attributed SBMs}{111}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Recap}{111}{subsection.6.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Future Work}{111}{subsection.6.3.2}}
\bibstyle{apalike}
\bibdata{dissBib}
\bibcite{snapdata}{{sna}{}{{}}{{}}}
\bibcite{newmandata}{{new}{}{{}}{{}}}
\bibcite{traaglouvain}{{tra}{}{{}}{{}}}
\bibcite{tiagoskewed}{{tia}{}{{}}{{}}}
\bibcite{detect25}{{5}{2016}{{Abbe et~al.}}{{}}}
\bibcite{slic}{{6}{2012}{{Achanta et~al.}}{{}}}
\bibcite{nimaFlow}{{7}{2013}{{Aghaeepour et~al.}}{{}}}
\bibcite{immuneClock}{{8}{2017}{{Aghaeepour et~al.}}{{}}}
\bibcite{aicher}{{9}{2014}{{Aicher et~al.}}{{}}}
\bibcite{aicher2015learning}{{10}{2015a}{{Aicher et~al.}}{{}}}
\bibcite{weightSBM}{{11}{2015b}{{Aicher et~al.}}{{}}}
\bibcite{mixMember}{{12}{2008}{{Airoldi et~al.}}{{}}}
\bibcite{vBayes}{{13}{2000}{{Attias}}{{}}}
\bibcite{moduleMicrobiome}{{14}{2016}{{Baldassano and Bassett}}{{}}}
\bibcite{barbillon}{{15}{2015}{{Barbillon et~al.}}{{}}}
\bibcite{varIntro}{{16}{2007}{{Barry et~al.}}{{}}}
\bibcite{detect38}{{17}{2011}{{Benaych-Georges and Nadakuditi}}{{}}}
\bibcite{cytof}{{18}{2012}{{Bendall et~al.}}{{}}}
\@writefile{toc}{\contentsline {chapter}{BIBLIOGRAPHY}{113}{section*.4}}
\bibcite{benderCanfield}{{19}{1978}{{Bender and Canfield}}{{}}}
\bibcite{Benson}{{20}{2016}{{Benson et~al.}}{{}}}
\bibcite{betzel}{{21}{2018}{{Betzel et~al.}}{{}}}
\bibcite{blondel}{{22}{2008}{{Blondel et~al.}}{{}}}
\bibcite{boccaletti2014structure}{{23}{2014}{{Boccaletti et~al.}}{{}}}
\bibcite{bonacci}{{24}{2014}{{Bonacci et~al.}}{{}}}
\bibcite{boon}{{25}{2014}{{Boon et~al.}}{{}}}
\bibcite{netensemble}{{26}{2011}{{Brandes et~al.}}{{}}}
\bibcite{structurenetwork}{{27}{2009}{{Brandes et~al.}}{{}}}
\bibcite{browet}{{28}{2011}{{Browet et~al.}}{{}}}
\bibcite{miSeq}{{29}{2012}{{Caporaso et~al.}}{{}}}
\bibcite{cytofkit}{{30}{2016}{{Chen et~al.}}{{}}}
\bibcite{clausethierarchy}{{31}{2007}{{Clauset et~al.}}{{}}}
\bibcite{ilouvain}{{32}{2015}{{Combe et~al.}}{{}}}
\bibcite{genetic}{{33}{2010}{{Costanzo et~al.}}{{}}}
\bibcite{commdeccompare}{{34}{2005a}{{Danon et~al.}}{{}}}
\bibcite{danon}{{35}{2005b}{{Danon et~al.}}{{}}}
\bibcite{dudin}{{36}{2008}{{Daudin et~al.}}{{}}}
\bibcite{manlio2}{{37}{2015a}{{De~Domenico et~al.}}{{}}}
\bibcite{domen}{{38}{2015b}{{De~Domenico et~al.}}{{}}}
\bibcite{manlioMathFoundations}{{39}{2013}{{De~Domenico et~al.}}{{}}}
\bibcite{decelle2011inference}{{40}{2011a}{{Decelle et~al.}}{{}}}
\bibcite{detect23}{{41}{2011b}{{Decelle et~al.}}{{}}}
\bibcite{dempster}{{42}{1977}{{Dempster et~al.}}{{}}}
\bibcite{collabComm}{{43}{2014}{{Deng et~al.}}{{}}}
\bibcite{cocluster}{{44}{2001}{{Dhillon}}{{}}}
\bibcite{dingcluster}{{45}{2014}{{Ding and Schloss}}{{}}}
\bibcite{microbeco}{{46}{2012}{{Faust et~al.}}{{}}}
\bibcite{pluralHom}{{47}{1981}{{Feld}}{{}}}
\bibcite{fortunato}{{48}{2010}{{Fortunato}}{{}}}
\bibcite{fortu2}{{49}{2016}{{Fortunato and Hric}}{{}}}
\bibcite{sparcc}{{50}{2012}{{Friedman and Alm}}{{}}}
\bibcite{detectTemporal}{{51}{2016}{{Ghasemian et~al.}}{{}}}
\bibcite{gilbert}{{52}{2004}{{Gilbert and Levchenko}}{{}}}
\bibcite{girvancommunity}{{53}{2002}{{Girvan and Newman}}{{}}}
\bibcite{gleichpagerank}{{54}{2015}{{Gleich}}{{}}}
\bibcite{socialnetwork}{{55}{2013}{{Greene and Cunningham}}{{}}}
\bibcite{node2vec}{{56}{2016}{{Grover and Leskovec}}{{}}}
\bibcite{guimera2009missing}{{57}{2009}{{Guimer{\`a} and Sales-Pardo}}{{}}}
\bibcite{airoldi}{{58}{2015}{{Han et~al.}}{{}}}
\bibcite{kMean}{{59}{1979}{{Hartigan and Wong}}{{}}}
\bibcite{hric}{{60}{2016}{{Hric et~al.}}{{}}}
\bibcite{detect22}{{61}{2012}{{Hu et~al.}}{{}}}
\bibcite{confusingMesoscopic}{{62}{2015}{{Iacovacci et~al.}}{{}}}
\bibcite{jakk}{{63}{2001}{{Jaakkola}}{{}}}
\bibcite{abby}{{64}{2014}{{Jacobs and Clauset}}{{}}}
\bibcite{jungirie}{{65}{2012}{{Jung et~al.}}{{}}}
\bibcite{degreecorrectSBM}{{66}{2011}{{Karrer and ~}}{{}}}
\bibcite{degreeCorrect}{{67}{2011}{{Karrer and Newman}}{{}}}
\bibcite{kempe}{{68}{2003}{{Kempe et~al.}}{{}}}
\bibcite{kivelamultilayer}{{69}{2014}{{Kivel{\"a} et~al.}}{{}}}
\bibcite{homophily}{{70}{2009}{{Kossinets and Watts}}{{}}}
\bibcite{microbiomedata}{{71}{2014}{{Lahti et~al.}}{{}}}
\bibcite{fortu1}{{72}{2009}{{Lancichinetti and Fortunato}}{{}}}
\bibcite{detect20}{{73}{2011}{{Lancichinetti and Fortunato}}{{}}}
\bibcite{picrust}{{74}{2013}{{Langille et~al.}}{{}}}
\bibcite{larremoreparasite}{{75}{2013}{{Larremore et~al.}}{{}}}
\bibcite{LA}{{76}{2011}{{Latouche et~al.}}{{}}}
\bibcite{networkMicrobiome}{{77}{2017}{{Layeghifard et~al.}}{{}}}
\bibcite{leskoveccommunity}{{78}{2009}{{Leskovec et~al.}}{{}}}
\bibcite{mutualism}{{79}{2008}{{Leung and Poulin}}{{}}}
\bibcite{phenoGraph}{{80}{2015}{{Levine et~al.}}{{}}}
\bibcite{supergenomic}{{81}{2014}{{Lisewski et~al.}}{{}}}
\bibcite{structural}{{82}{1971}{{Lorrain and White}}{{}}}
\bibcite{TwoD}{{83}{2008}{{Maaten and Hinton}}{{}}}
\bibcite{biclustering}{{84}{2004}{{Madeira and Oliveira}}{{}}}
\bibcite{intraTumor}{{85}{2012}{{Marusyk et~al.}}{{}}}
\bibcite{gini}{{86}{2009}{{Menze et~al.}}{{}}}
\bibcite{laplacian}{{87}{1994}{{Merris}}{{}}}
\bibcite{hierarchicalmod}{{88}{2009}{{Meunier et~al.}}{{}}}
\bibcite{word2Vec}{{89}{2013}{{Mikolov et~al.}}{{}}}
\bibcite{muchamultislice}{{90}{2010}{{Mucha et~al.}}{{}}}
\bibcite{belief}{{91}{1999}{{Murphy et~al.}}{{}}}
\bibcite{detect24}{{92}{2012}{{Nadakuditi and Newman}}{{}}}
\bibcite{detect39}{{93}{2013}{{Nadakuditi and Newman}}{{}}}
\bibcite{newmanAssort}{{94}{2002}{{Newman}}{{}}}
\bibcite{newman2006modularity}{{95}{2006a}{{Newman}}{{}}}
\bibcite{newmanmodularity}{{96}{2006b}{{Newman}}{{}}}
\bibcite{clauset}{{97}{2016}{{Newman and Clauset}}{{}}}
\bibcite{newmangirvan}{{98}{2004}{{Newman and Girvan}}{{}}}
\bibcite{newmanspectral}{{99}{2006c}{{Newman}}{{}}}
\bibcite{NONCluster}{{100}{2015}{{Ni et~al.}}{{}}}
\bibcite{rWalk}{{101}{2004}{{Noh and Rieger}}{{}}}
\bibcite{taxonomy}{{102}{2012}{{Onnela et~al.}}{{}}}
\bibcite{mlsbm1}{{103}{2015}{{Paul and Chen}}{{}}}
\bibcite{peelChange}{{104}{2015}{{Peel and Clauset}}{{}}}
\bibcite{peel2017ground}{{105}{2017}{{Peel et~al.}}{{}}}
\bibcite{peixotoHierarchAttribute}{{106}{2013}{{Peixoto}}{{}}}
\bibcite{tiagosbm}{{107}{2014}{{Peixoto}}{{}}}
\bibcite{thiagomlsbm}{{108}{2015}{{Peixoto}}{{}}}
\bibcite{peix}{{109}{2018}{{Peixoto}}{{}}}
\bibcite{peng}{{110}{2014}{{Peng et~al.}}{{}}}
\bibcite{deepWalk}{{111}{2014}{{Perozzi et~al.}}{{}}}
\bibcite{porter2009communities}{{112}{2009a}{{Porter et~al.}}{{}}}
\bibcite{community}{{113}{2009b}{{Porter et~al.}}{{}}}
\bibcite{detectDegreeHetero}{{114}{2013}{{Radicchi}}{{}}}
\bibcite{resParam}{{115}{2006}{{Reichardt and Bornholdt}}{{}}}
\bibcite{detect21}{{116}{2008}{{Reichardt and Leone}}{{}}}
\bibcite{rombach2014core}{{117}{2014}{{Rombach et~al.}}{{}}}
\bibcite{VI}{{118}{2007}{{Rosenberg and Hirschberg}}{{}}}
\bibcite{HierarchAttl}{{119}{2013}{{Sarkar et~al.}}{{}}}
\bibcite{shaicase}{{120}{2017}{{Shai et~al.}}{{}}}
\bibcite{collabFilterReview}{{121}{2014}{{Shi et~al.}}{{}}}
\bibcite{originalSBM}{{122}{1997a}{{Snijders and Nowicki}}{{}}}
\bibcite{SBM}{{123}{1997b}{{Snijders and Nowicki}}{{}}}
\bibcite{linkComm}{{124}{2012}{{Soundarajan and Hopcroft}}{{}}}
\bibcite{compressing}{{125}{2017}{{Stanley et~al.}}{{}}}
\bibcite{smlsbm}{{126}{2016}{{Stanley et~al.}}{{}}}
\bibcite{taylor2015enhanced}{{127}{2015}{{Taylor et~al.}}{{}}}
\bibcite{gap}{{128}{2001}{{Tibshirani et~al.}}{{}}}
\bibcite{RWR}{{129}{2008}{{Tong et~al.}}{{}}}
\bibcite{Rand}{{130}{2011}{{Traud et~al.}}{{}}}
\bibcite{motiffinding}{{131}{2006}{{Tsuda and Kudo}}{{}}}
\bibcite{microbiome}{{132}{2007}{{Turnbaugh et~al.}}{{}}}
\bibcite{ugander2013subgraph}{{133}{2013}{{Ugander et~al.}}{{}}}
\bibcite{catala}{{134}{2016}{{Valles-Catala et~al.}}{{}}}
\bibcite{hub}{{135}{2013}{{van~den Heuvel and Sporns}}{{}}}
\bibcite{walsh2017}{{136}{2017}{{Walsh et~al.}}{{}}}
\bibcite{linkPredReview}{{137}{2014}{{Wang et~al.}}{{}}}
\bibcite{sbmdirect}{{138}{1987}{{Wang and Wong}}{{}}}
\bibcite{spectral1}{{139}{2008}{{Xiang and Gong}}{{}}}
\bibcite{affil}{{140}{2012}{{Yang and Leskovec}}{{}}}
\bibcite{bigclam}{{141}{2013}{{Yang and Leskovec}}{{}}}
\bibcite{jureTruth}{{142}{2015}{{Yang and Leskovec}}{{}}}
\bibcite{cesna}{{143}{2013}{{Yang et~al.}}{{}}}
\bibcite{SuperNodeSide}{{144}{2017}{{Yang et~al.}}{{}}}
\bibcite{your}{{145}{2014}{{Yourstone et~al.}}{{}}}
\bibcite{antagonism}{{146}{2015}{{Zapi{\'e}n-Campos et~al.}}{{}}}
\bibcite{FlowSpectral}{{147}{2010}{{Zare et~al.}}{{}}}
\bibcite{CoreHD}{{148}{2016}{{Zdeborov{\'a} et~al.}}{{}}}
\bibcite{comp}{{149}{2012}{{Zhang et~al.}}{{}}}
\bibcite{ohmNet}{{150}{2017}{{Zitnik and Leskovec}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
